{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplenn.optim.qlearning import ReplayMemory\n",
    "from simplenn.optim.qlearning import QLearning\n",
    "from simplenn.optim.qlearning import DoubleQLearning\n",
    "from simplenn.optim.qlearning import FixedTargetQLearning\n",
    "from simplenn.optim.qlearning import FixedTargetDoubleQLearningSymmetric\n",
    "from simplenn.optim.qlearning import FixedTargetDoubleQLearningAsymmetric\n",
    "from simplenn.optim.qlearning import BaseSimulation\n",
    "\n",
    "from simplenn.structures.qfunction import QTable\n",
    "from simplenn.structures.qfunction import DiscretizedQTable\n",
    "from simplenn.structures.qfunction import AutoDiscretizingQTable\n",
    "from simplenn.structures.qfunction import AggregateQFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = gym.make('MountainCar-v0')\n",
    "#env = gym.make('Acrobot-v1')\n",
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config dict\n",
    "config = {}\n",
    "\n",
    "# Basic parameters\n",
    "config[\"gamma\"] = 0.95\n",
    "config[\"defaultVal\"] = 0.0\n",
    "\n",
    "# Learning rate related parameters\n",
    "config[\"alphaRate\"] = 0.75\n",
    "config[\"alphaCutoff\"] = 0.0\n",
    "\n",
    "# Exploration related parameters\n",
    "config[\"epsInit\"] = 1.0\n",
    "config[\"epsFinal\"] = 0.2\n",
    "config[\"epsRampLen\"] = 10\n",
    "\n",
    "# Auto-discretization related parameters\n",
    "config[\"maxObsPerLeaf\"] = 16\n",
    "config[\"maxLeafNodes\"] = 30*10**3\n",
    "config[\"splitResetMode\"] = AutoDiscretizingQTable.MODE_0\n",
    "\n",
    "# Experience replay related parameters\n",
    "config[\"replayMemMaxSize\"] = 100 * env.env.spec.max_episode_steps\n",
    "config[\"replayMemMinSize\"] = 100 * env.env.spec.max_episode_steps\n",
    "config[\"replayMemMode\"] = ReplayMemory.MODE_CYCLING\n",
    "\n",
    "# Fixed Q-target related parameters\n",
    "config[\"targetQUpdateFreq\"] = 25 * env.env.spec.max_episode_steps\n",
    "\n",
    "# Simulation duration\n",
    "config[\"nEpisodes\"] = 50000\n",
    "\n",
    "# Evaluation related parameters\n",
    "config[\"nTest\"] = 250\n",
    "config[\"verboseFreq\"] = 5000\n",
    "config[\"recordFreq\"] = 5000\n",
    "\n",
    "# Wandb only parameters\n",
    "config[\"envId\"] = env.env.spec.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCartPos = 50\n",
    "nCartV = 100\n",
    "nPoleAngle = 100\n",
    "nPoleV = 100\n",
    "\n",
    "obs_space = env.observation_space\n",
    "\n",
    "artMaxCartV = 5.0\n",
    "artMinCartV = -artMaxCartV\n",
    "artMaxPoleV = 10.0\n",
    "artMinPoleV = -artMaxPoleV\n",
    "\n",
    "qCartPos = (obs_space.high[0] - obs_space.low[0]) / nCartPos\n",
    "qCartV = (artMaxCartV - artMinCartV) / nCartV\n",
    "qPoleAngle = (obs_space.high[2] - obs_space.low[2]) / nPoleAngle\n",
    "qPoleV = (artMaxPoleV - artMinPoleV) / nPoleV\n",
    "\n",
    "config[\"quantums\"] = [qCartPos, qCartV, qPoleAngle, qPoleV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doLearning(config):\n",
    "    \n",
    "#    Q = AutoDiscretizingQTable(\n",
    "#        range(env.action_space.n),\n",
    "#        config[\"gamma\"],\n",
    "#        config[\"alphaRate\"],\n",
    "#        config[\"alphaCutoff\"],\n",
    "#        config[\"epsInit\"],\n",
    "#        config[\"epsFinal\"],\n",
    "#        config[\"epsRampLen\"],\n",
    "#        config[\"defaultVal\"],\n",
    "#        config[\"maxObsPerLeaf\"],\n",
    "#        config[\"maxLeafNodes\"],\n",
    "#        config[\"splitResetMode\"]\n",
    "#    )\n",
    "    Q = DiscretizedQTable(\n",
    "        range(env.action_space.n),\n",
    "        config[\"gamma\"],\n",
    "        config[\"alphaRate\"],\n",
    "        config[\"alphaCutoff\"],\n",
    "        config[\"epsInit\"],\n",
    "        config[\"epsFinal\"],\n",
    "        config[\"epsRampLen\"],\n",
    "        config[\"defaultVal\"],\n",
    "        config[\"quantums\"]\n",
    "    )\n",
    "    config[\"qfunctionClass\"] = Q.__class__.__name__\n",
    "    \n",
    "    replayMem = ReplayMemory(\n",
    "        config[\"replayMemMaxSize\"], \n",
    "        config[\"replayMemMinSize\"], \n",
    "        config[\"replayMemMode\"]\n",
    "    )\n",
    "    \n",
    "#    algo = QLearning(Q, replayMem)\n",
    "    algo = DoubleQLearning(Q, replayMem)\n",
    "#    algo = FixedTargetQLearning(Q, replayMem, config[\"targetQUpdateFreq\"])\n",
    "#    algo = FixedTargetDoubleQLearningSymmetric(Q, replayMem, config[\"targetQUpdateFreq\"])\n",
    "#    algo = FixedTargetDoubleQLearningAsymmetric(Q, replayMem, config[\"targetQUpdateFreq\"])\n",
    "    config[\"algoClass\"] = algo.__class__.__name__\n",
    "    \n",
    "    wandb.init(project=\"simple_rl\", config=config)\n",
    "    \n",
    "    algo.learn(\n",
    "        env, \n",
    "        config[\"nEpisodes\"], \n",
    "        config[\"nTest\"], \n",
    "        config[\"verboseFreq\"], \n",
    "        config[\"recordFreq\"], \n",
    "        wandb\n",
    "    )\n",
    "    \n",
    "    return (Q, algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nRuns = 3\n",
    "\n",
    "for i in range(nRuns):\n",
    "    \n",
    "    print(f\"{i+1}/{nRuns}\")\n",
    "    Q, algo = doLearning(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 381.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score: {algo.performEpisode(env, render=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean     401.300000\n",
       "std       36.084267\n",
       "min      280.000000\n",
       "25%      376.250000\n",
       "50%      396.500000\n",
       "75%      422.000000\n",
       "max      500.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([algo.performEpisode(env) for _ in range(config[\"nTest\"])]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score and nStates evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7aa7c11090>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getActualQ(Q):\n",
    "    return Q if not isinstance(Q, AggregateQFunction) else Q.Qs[0]\n",
    "\n",
    "scores = [np.mean([BaseSimulation(q).performEpisode(env) for _ in range(config[\"nTest\"])]) for q in algo.qs]\n",
    "nStates = [len(getActualQ(q).data) for q in algo.qs]\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    \"Score\":pd.Series(scores),\n",
    "    \"nStates\":pd.Series(nStates)\n",
    "})\n",
    "\n",
    "ax = df.plot(y=\"Score\")\n",
    "df.plot(y=\"nStates\", secondary_y=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Values distribution (Simple Q-Learning only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7af442b590>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = []\n",
    "\n",
    "for s, sData in getActualQ(algo.Q).data.items():\n",
    "    qs += [aData[Q.Q_IDX] for a, aData in sData.items()]\n",
    "\n",
    "pd.Series(qs).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions visit count distribution (Simple Q-Learning only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7af4080710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = []\n",
    "\n",
    "for s, sData in getActualQ(algo.Q).data.items():\n",
    "    ns += [aData[Q.N_IDX] for a, aData in sData.items()]\n",
    "\n",
    "pd.Series(ns).hist(bins=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrepancies between Qa and Qb (Double Q-Learning only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-efec907e2f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_IDX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnMid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mna\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/simple_rl/simplerl/qfunction/autodiscretizingqtable.py\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(self, s, a)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \"\"\"\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/simple_rl/simplerl/qfunction/autodiscretizingqtable.py\u001b[0m in \u001b[0;36mgetLeafNode\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnextNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitIdx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnextNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitIdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnextNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitVal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0mnextNode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnextNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextNode1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Does not work on auto-dicretized QTables.\n",
    "\n",
    "actions = set()\n",
    "\n",
    "Qa = algo.qs[-1].Qs[0]\n",
    "Qb = algo.qs[-1].Qs[1]\n",
    "\n",
    "for s, sData in Qa.data.items():\n",
    "    for a, aData in sData.items():\n",
    "        actions.add((s, a))\n",
    "\n",
    "for s, sData in Qb.data.items():\n",
    "    for a, aData in sData.items():\n",
    "        actions.add((s, a))\n",
    "\n",
    "nDiff = []\n",
    "qDiff = []\n",
    "\n",
    "for s, a in actions:\n",
    "    \n",
    "    na = Qa.getData(s, a).get(Qa.N_IDX, 0)\n",
    "    nb = Qb.getData(s, a).get(Qb.N_IDX, 0)\n",
    "    nMid = (na + nb) / 2.0\n",
    "    \n",
    "    qa = Qa.getData(s, a).get(Qa.Q_IDX, 0.0)\n",
    "    qb = Qb.getData(s, a).get(Qb.Q_IDX, 0.0)\n",
    "    qMid = (qa + qb) / 2.0\n",
    "    \n",
    "    if na > 5 and nb > 5:\n",
    "        nDiff.append(abs(nb - nMid) / nMid)\n",
    "    if na > 0 and nb > 0:\n",
    "        qDiff.append(abs(qb - qMid) / qMid)\n",
    "\n",
    "pd.Series(nDiff).hist(bins=100, density=True, cumulative=True)\n",
    "#pd.Series(qDiff).hist(bins=100, density=True, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Administrative tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(\"jrmsayag/simple_rl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    run.config[\"alphaCutoff\"] = 0.0\n",
    "    run.config[\"algoClass\"] = QLearning.__name__\n",
    "    run.config[\"qfunctionClass\"] = DiscretizedQTable.__name__\n",
    "    run.tags.clear()\n",
    "    run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
